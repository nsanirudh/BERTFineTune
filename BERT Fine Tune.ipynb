{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b5d9eb",
   "metadata": {},
   "source": [
    "<h2 align=center> Fine-Tune BERT for Text Classification with TensorFlow</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d6f7a",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
    "    <p style=\"text-align: center;color:gray\">Figure 1: BERT Classification Model</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92968fe8",
   "metadata": {},
   "source": [
    "In this [project](https://www.coursera.org/projects/fine-tune-bert-tensorflow/), you will learn how to fine-tune a BERT model for text classification using TensorFlow and TF-Hub.\n",
    "\n",
    "[link text](https://)The pretrained BERT model used in this project is [available](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2) on [TensorFlow Hub](https://tfhub.dev/).\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the time you complete this project, you will be able to:\n",
    "\n",
    "- Build TensorFlow Input Pipelines for Text Data with the [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) API\n",
    "- Tokenize and Preprocess Text for BERT\n",
    "- Fine-tune BERT for text classification with TensorFlow 2 and [TF Hub](https://tfhub.dev)\n",
    "\n",
    "In order to be successful with this project, it is assumed you are:\n",
    "\n",
    "- Competent in the Python programming language\n",
    "- Familiar with deep learning for Natural Language Processing (NLP)\n",
    "- Familiar with TensorFlow, and its Keras API\n",
    "\n",
    "This project/notebook consists of several Tasks.\n",
    "\n",
    "- **[Task 1]()**: Introduction to the Project.\n",
    "- **[Task 2]()**: Setup your TensorFlow and Colab Runtime\n",
    "- **[Task 3]()**: Download and Import the Quora Insincere Questions Dataset\n",
    "- **[Task 4]()**: Create tf.data.Datasets for Training and Evaluation\n",
    "- **[Task 5]()**: Download a Pre-trained BERT Model from TensorFlow Hub\n",
    "- **[Task 6]()**: Tokenize and Preprocess Text for BERT\n",
    "- **[Task 7]()**: Wrap a Python Function into a TensorFlow op for Eager Execution\n",
    "- **[Task 8]()**: Create a TensorFlow Input Pipeline with `tf.data`\n",
    "- **[Task 9]()**: Add a Classification Head to the BERT `hub.KerasLayer`\n",
    "- **[Task 10]()**: Fine-Tune BERT for Text Classification\n",
    "- **[Task 11]()**: Evaluate the BERT Text Classification Model\n",
    "\n",
    "## Task 2: Setup your TensorFlow and Colab Runtime.\n",
    "\n",
    "You will only be able to use the Colab Notebook after you save it to your Google Drive folder. Click on the File menu and select “Save a copy in Drive…\n",
    "\n",
    "![Copy to Drive](https://drive.google.com/uc?id=1CH3eDmuJL8WR0AP1r3UE6sOPuqq8_Wl7)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "### Check GPU Availability\n",
    "\n",
    "Check if your Colab notebook is configured to use Graphical Processing Units (GPUs). If zero GPUs are available, check if the Colab notebook is configured to use GPUs (Menu > Runtime > Change Runtime Type).\n",
    "\n",
    "![Hardware Accelerator Settings](https://drive.google.com/uc?id=1qrihuuMtvzXJHiRV8M7RngbxFYipXKQx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2248bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 28 23:47:53 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 471.96       Driver Version: 471.96       CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   52C    P8    14W /  N/A |    331MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1768    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A      3468    C+G   ...kzcwy\\mcafee-security.exe    N/A      |\n",
      "|    0   N/A  N/A      4172    C+G   ...zpdnekdrzrea0\\Spotify.exe    N/A      |\n",
      "|    0   N/A  N/A      9600    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     12116    C+G   ...artMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     12700    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     14072    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "|    0   N/A  N/A     14968    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     15232    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     19448    C+G   ...\\Programs\\Blitz\\Blitz.exe    N/A      |\n",
      "|    0   N/A  N/A     21036    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
      "|    0   N/A  N/A     21392    C+G   ... WARP\\Cloudflare WARP.exe    N/A      |\n",
      "|    0   N/A  N/A     22924    C+G   ...\\app-1.0.9003\\Discord.exe    N/A      |\n",
      "|    0   N/A  N/A     26052    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     26152    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     26244    C+G   ...2\\jbr\\bin\\jcef_helper.exe    N/A      |\n",
      "|    0   N/A  N/A     27052    C+G   ...t\\Teams\\current\\Teams.exe    N/A      |\n",
      "|    0   N/A  N/A     34348    C+G   ...ekyb3d8bbwe\\HxOutlook.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec91e0",
   "metadata": {},
   "source": [
    "### Install TensorFlow and TensorFlow Model Garden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3440f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca5900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f0d3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'models' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c891bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\users\\\\anirudh\\\\pycharmprojects\\\\bertfinetune\\\\venv\\\\lib\\\\site-packages\\\\~-mpy\\\\.libs\\\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll'\n",
      "Check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install requirements to use tensorflow/models repository\n",
    "!pip install -Uqr models/official/requirements.txt\n",
    "# you may have to restart the runtime afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55d5fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.4.0 and strictly below 2.7.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.3.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import sys\n",
    "sys.path.append('models')\n",
    "from official.nlp.data import classifier_data_lib\n",
    "from official.nlp.bert import tokenization\n",
    "from official.nlp import optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c169de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version:  2.3.0\n",
      "Eager mode:  True\n",
      "Hub version:  0.12.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(\"TF Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35514b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Stellargraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc6a66",
   "metadata": {},
   "source": [
    "## Task 3: Download and Import the Quora Insincere Questions Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8d9778",
   "metadata": {},
   "source": [
    "**A** downloadable copy of the [Quora Insincere Questions Classification data](https://www.kaggle.com/c/quora-insincere-questions-classification/data) can be found [https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip](https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip). Decompress and read the data into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "271cede1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1306102</th>\n",
       "      <td>ffff3778790af9baae76</td>\n",
       "      <td>What steps can I take to live a normal life if...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306103</th>\n",
       "      <td>ffff3f0a2449ffe4b9ff</td>\n",
       "      <td>Isn't Trump right after all? Why should the US...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306104</th>\n",
       "      <td>ffff41393389d4206066</td>\n",
       "      <td>Is 33 too late for a career in creative advert...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306105</th>\n",
       "      <td>ffff42493fc203cd9532</td>\n",
       "      <td>What is difference between the filteration wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306106</th>\n",
       "      <td>ffff48dd47bee89fff79</td>\n",
       "      <td>If the universe \"popped\" into existence from n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306107</th>\n",
       "      <td>ffff5fd051a032f32a39</td>\n",
       "      <td>How does a shared service technology team meas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306108</th>\n",
       "      <td>ffff6d528040d3888b93</td>\n",
       "      <td>How is DSATM civil engineering?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306109</th>\n",
       "      <td>ffff8776cd30cdc8d7f8</td>\n",
       "      <td>Do you know any problem that depends solely on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306110</th>\n",
       "      <td>ffff94d427ade3716cd1</td>\n",
       "      <td>What are some comic ideas for you Tube videos ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306111</th>\n",
       "      <td>ffffa382c58368071dc9</td>\n",
       "      <td>If you had $10 million of Bitcoin, could you s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306112</th>\n",
       "      <td>ffffa5b0fa76431c063f</td>\n",
       "      <td>Are you ashamed of being an Indian?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306113</th>\n",
       "      <td>ffffae5dbda3dc9e9771</td>\n",
       "      <td>What are the methods to determine fossil ages ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306114</th>\n",
       "      <td>ffffba7c4888798571c1</td>\n",
       "      <td>What is your story today?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306115</th>\n",
       "      <td>ffffc0c7158658a06fd9</td>\n",
       "      <td>How do I consume 150 gms protein daily both ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306116</th>\n",
       "      <td>ffffc404da586ac5a08f</td>\n",
       "      <td>What are the good career options for a msc che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306119</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306120</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306121</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "1306102  ffff3778790af9baae76   \n",
       "1306103  ffff3f0a2449ffe4b9ff   \n",
       "1306104  ffff41393389d4206066   \n",
       "1306105  ffff42493fc203cd9532   \n",
       "1306106  ffff48dd47bee89fff79   \n",
       "1306107  ffff5fd051a032f32a39   \n",
       "1306108  ffff6d528040d3888b93   \n",
       "1306109  ffff8776cd30cdc8d7f8   \n",
       "1306110  ffff94d427ade3716cd1   \n",
       "1306111  ffffa382c58368071dc9   \n",
       "1306112  ffffa5b0fa76431c063f   \n",
       "1306113  ffffae5dbda3dc9e9771   \n",
       "1306114  ffffba7c4888798571c1   \n",
       "1306115  ffffc0c7158658a06fd9   \n",
       "1306116  ffffc404da586ac5a08f   \n",
       "1306117  ffffcc4e2331aaf1e41e   \n",
       "1306118  ffffd431801e5a2f4861   \n",
       "1306119  ffffd48fb36b63db010c   \n",
       "1306120  ffffec519fa37cf60c78   \n",
       "1306121  ffffed09fedb5088744a   \n",
       "\n",
       "                                             question_text  target  \n",
       "1306102  What steps can I take to live a normal life if...       0  \n",
       "1306103  Isn't Trump right after all? Why should the US...       1  \n",
       "1306104  Is 33 too late for a career in creative advert...       0  \n",
       "1306105  What is difference between the filteration wor...       0  \n",
       "1306106  If the universe \"popped\" into existence from n...       0  \n",
       "1306107  How does a shared service technology team meas...       0  \n",
       "1306108                    How is DSATM civil engineering?       0  \n",
       "1306109  Do you know any problem that depends solely on...       0  \n",
       "1306110  What are some comic ideas for you Tube videos ...       0  \n",
       "1306111  If you had $10 million of Bitcoin, could you s...       0  \n",
       "1306112                Are you ashamed of being an Indian?       1  \n",
       "1306113  What are the methods to determine fossil ages ...       0  \n",
       "1306114                          What is your story today?       0  \n",
       "1306115  How do I consume 150 gms protein daily both ve...       0  \n",
       "1306116  What are the good career options for a msc che...       0  \n",
       "1306117  What other technical skills do you need as a c...       0  \n",
       "1306118  Does MS in ECE have good job prospects in USA ...       0  \n",
       "1306119                          Is foam insulation toxic?       0  \n",
       "1306120  How can one start a research project based on ...       0  \n",
       "1306121  Who wins in a battle between a Wolverine and a...       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"https://archive.org/download/fine-tune-bert-tensorflow-train.csv/train.csv.zip\",\n",
    "                compression='zip',low_memory=False )\n",
    "df.shape\n",
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eb3b310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Target Distribution'}, ylabel='Frequency'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.target.plot(kind='hist', title='Target Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409f489",
   "metadata": {},
   "source": [
    "## Task 4: Create tf.data.Datasets for Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9328ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df , remaining = train_test_split(df, random_state=42, train_size=0.0075, stratify=df.target.values)\n",
    "valid_df , _ = train_test_split(remaining, random_state=42, train_size=0.00075, stratify=remaining.target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02e07f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9795, 3), (972, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc8e9570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Why are unhealthy relationships so desirable?', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(b'Can Austin Davis tell me how to get a job in the oil and gas industry?', shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    train_data =tf.data.Dataset.from_tensor_slices((train_df['question_text'].values, train_df['target'].values))\n",
    "    val_data =tf.data.Dataset.from_tensor_slices((valid_df['question_text'].values, valid_df['target'].values))\n",
    "    \n",
    "    for text, label in train_data.take(1):\n",
    "        print(text)\n",
    "        print(label)\n",
    "        \n",
    "    for text, label in val_data.take(1):\n",
    "        print(text)\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395663f",
   "metadata": {},
   "source": [
    "## Task 5: Download a Pre-trained BERT Model from TensorFlow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26054688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Each line of the dataset is composed of the review text and its label\n",
    "- Data preprocessing consists of transforming text to BERT input features:\n",
    "input_word_ids, input_mask, segment_ids\n",
    "- In the process, tokenizing the text is done with the provided BERT model tokenizer\n",
    "\"\"\"\n",
    "\n",
    " # Label categories\n",
    " # maximum length of (token) input sequences\n",
    "label_list = [0,1]\n",
    "max_seq_len = 128\n",
    "train_batch_size = 32\n",
    "\n",
    "# Get BERT layer and tokenizer:\n",
    "# More details here: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\", trainable=True)\n",
    "\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf5b4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hey', '##,', 'how', 'are', 'you', 'doing', '##?']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.wordpiece_tokenizer.tokenize('hey, how are you doing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2ddbd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4931, 29623, 2129, 2024, 2017, 2725, 29632]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokenizer.wordpiece_tokenizer.tokenize('hey, how are you doing?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66868bb5",
   "metadata": {},
   "source": [
    "## Task 6: Tokenize and Preprocess Text for BERT\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img width=\"512px\" src='https://drive.google.com/uc?id=1-SpKFELnEvBMBqO7h3iypo8q9uUUo96P' />\n",
    "    <p style=\"text-align: center;color:gray\">Figure 2: BERT Tokenizer</p>\n",
    "</div>\n",
    "\n",
    "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create InputExamples using `classifier_data_lib`'s constructor `InputExample` provided in the BERT library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1be02adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This provides a function to convert row to input features and label\n",
    "\n",
    "def to_feature(text, label, label_list=label_list, max_seq_length=max_seq_len, tokenizer=tokenizer):\n",
    "    example = classifier_data_lib.InputExample(guid=None,\n",
    "                                              text_a = text.numpy(),\n",
    "                                              text_b = None,\n",
    "                                              label = label.numpy())\n",
    "    feature = classifier_data_lib.convert_single_example(0, example, label_list, max_seq_length, tokenizer)\n",
    "#     print(type(feature.label_id))\n",
    "#     print(type(feature.input_ids))\n",
    "#     print(type(feature.input_mask))\n",
    "#     print(type(feature.segment_ids))\n",
    "    return (feature.input_ids, feature.input_mask, feature.segment_ids, feature.label_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ba8176",
   "metadata": {},
   "source": [
    "You want to use [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) to apply this function to each element of the dataset. [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) runs in graph mode.\n",
    "\n",
    "- Graph tensors do not have a value.\n",
    "- In graph mode you can only use TensorFlow Ops and functions.\n",
    "\n",
    "So you can't `.map` this function directly: You need to wrap it in a [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function). The [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function) will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94adfc82",
   "metadata": {},
   "source": [
    "## Task 7: Wrap a Python Function into a TensorFlow op for Eager Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c69c8291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_feature_map(text, label):\n",
    "    input_ids, input_mask, segment_ids, label_ids = tf.py_function(to_feature, inp=[text, label],\n",
    "                                                                  Tout=[tf.int32, tf.int32 ,tf.int32, tf.int32])\n",
    "    input_ids.set_shape([max_seq_len])\n",
    "    input_mask.set_shape([max_seq_len])\n",
    "    segment_ids.set_shape([max_seq_len])\n",
    "    label_ids.set_shape([])\n",
    "    \n",
    "    x = {\n",
    "        'input_word_ids': input_ids,\n",
    "        'input_mask': input_mask,\n",
    "        'input_type_ids': segment_ids\n",
    "    }\n",
    "    \n",
    "    return (x, label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a906cb",
   "metadata": {},
   "source": [
    "## Task 8: Create a TensorFlow Input Pipeline with `tf.data`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "093bb290",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    C:\\Users\\anirudh\\AppData\\Local\\Temp/ipykernel_31432/1147152088.py:2 to_feature_map  *\n        input_ids, input_mask, segment_ids, label_ids = tf.py_function(to_feature, inp=[text, label],\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py:457 eager_py_func\n        func=func, inp=inp, Tout=Tout, eager=True, name=name)\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py:342 _internal_py_func\n        name=name)\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py:70 eager_py_func\n        name=name)\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:445 _apply_op_helper\n        \"%s that are invalid. Tensors: %s\" % (prefix, values))\n\n    TypeError: Tensors in list passed to 'input' of 'EagerPyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>, int32] that are invalid. Tensors: [{'input_word_ids': <tf.Tensor 'args_2:0' shape=(32, 128) dtype=int32>, 'input_mask': <tf.Tensor 'args_0:0' shape=(32, 128) dtype=int32>, 'input_type_ids': <tf.Tensor 'args_1:0' shape=(32, 128) dtype=int32>}, <tf.Tensor 'args_3:0' shape=(32,) dtype=int32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_31432/922954618.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[1;31m# train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m   train_data = (train_data.map(to_feature_map,\n\u001b[1;32m----> 4\u001b[1;33m                               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[0;32m   1700\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1701\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1702\u001b[1;33m           preserve_cardinality=True)\n\u001b[0m\u001b[0;32m   1703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[0;32m   4082\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4083\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4084\u001b[1;33m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[0;32m   4085\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4086\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"default\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3369\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3370\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3371\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2937\u001b[0m     \"\"\"\n\u001b[0;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[1;32m-> 2939\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2941\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2905\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2906\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3075\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3362\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3363\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3364\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3365\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3366\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3297\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3299\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3300\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3301\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    C:\\Users\\anirudh\\AppData\\Local\\Temp/ipykernel_31432/1147152088.py:2 to_feature_map  *\n        input_ids, input_mask, segment_ids, label_ids = tf.py_function(to_feature, inp=[text, label],\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py:457 eager_py_func\n        func=func, inp=inp, Tout=Tout, eager=True, name=name)\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py:342 _internal_py_func\n        name=name)\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_script_ops.py:70 eager_py_func\n        name=name)\n    c:\\users\\anirudh\\pycharmprojects\\bertfinetune\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:445 _apply_op_helper\n        \"%s that are invalid. Tensors: %s\" % (prefix, values))\n\n    TypeError: Tensors in list passed to 'input' of 'EagerPyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>, int32] that are invalid. Tensors: [{'input_word_ids': <tf.Tensor 'args_2:0' shape=(32, 128) dtype=int32>, 'input_mask': <tf.Tensor 'args_0:0' shape=(32, 128) dtype=int32>, 'input_type_ids': <tf.Tensor 'args_1:0' shape=(32, 128) dtype=int32>}, <tf.Tensor 'args_3:0' shape=(32,) dtype=int32>]\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "  # train\n",
    "  train_data = (train_data.map(to_feature_map,\n",
    "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "               \n",
    "    .shuffle(1000)\n",
    "    .batch(32, drop_remainder=True)           \n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "    \n",
    "  # valid\n",
    "  val_data = (val_data.map(to_feature_map,\n",
    "                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "               \n",
    "    .batch(32, drop_remainder=True)           \n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec45956",
   "metadata": {},
   "source": [
    "The resulting `tf.data.Datasets` return `(features, labels)` pairs, as expected by [`keras.Model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41163c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
       "  'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
       "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data spec\n",
    "train_data.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b77e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
       "  'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
       "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
       " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid data spec\n",
    "val_data.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f948ea9a",
   "metadata": {},
   "source": [
    "## Task 9: Add a Classification Head to the BERT Layer\n",
    "<div align=\"center\">\n",
    "    <img width=\"512px\" src='https://drive.google.com/uc?id=1fnJTeJs5HUpz7nix-F9E6EZdgUflqyEu' />\n",
    "    <p style=\"text-align: center;color:gray\">Figure 3: BERT Layer</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e195791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "def create_model():\n",
    "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32,\n",
    "                                       name=\"input_word_ids\")\n",
    "  input_mask = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32,\n",
    "                                   name=\"input_mask\")\n",
    "  input_type_ids = tf.keras.layers.Input(shape=(max_seq_len,), dtype=tf.int32,\n",
    "                                    name=\"input_type_ids\")\n",
    "  pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, input_type_ids])\n",
    "  drop = tf.keras.layers.Dropout(0.4)(pooled_output)\n",
    "  output = tf.keras.layers.Dense(1, activation='sigmoid', name=\"output\")(drop)\n",
    "\n",
    "  model = tf.keras.Model(\n",
    "      inputs ={\n",
    "          'input_words_ids': input_word_ids,\n",
    "          'input_mask': input_mask,\n",
    "          'input_type_ids': input_type_ids\n",
    "      },\n",
    "      outputs=output\n",
    "  )\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4630cc67",
   "metadata": {},
   "source": [
    "## Task 10: Fine-Tune BERT for Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c40d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model=model, show_shapes=True, dpi=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34943fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "epochs=4\n",
    "history = model.fit(train_data,\n",
    "                    validation_data=val_data,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e77a25b",
   "metadata": {},
   "source": [
    "## Task 11: Evaluate the BERT Text Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "  plt.plot(history.history[metric])\n",
    "  plt.plot(history.history['val_'+metric], '')\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(metric)\n",
    "  plt.legend([metric, 'val_'+metric])\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
